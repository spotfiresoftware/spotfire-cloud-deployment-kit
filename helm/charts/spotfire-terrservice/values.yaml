# Default values for terrservice.
# This is a YAML-formatted file.
# Declare variables to pass to your templates.

## @param global.spotfire.image.registry The global container image registry.
## @param global.spotfire.image.pullSecrets The global container registry secret names as an array.
##
global:
  spotfire:
    image:
      # global.spotfire.image.registry -- The global container image registry. Used for tibco/spotfire container images, unless it is overridden.
      registry:
      # global.spotfire.image.pullPolicy -- The global container image pull policy.
      pullPolicy: IfNotPresent
      # global.spotfire.image.pullSecrets -- The global container image pull secrets.
      ## E.g.
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##
      pullSecrets: []
  serviceName: terrservice

nodemanagerConfig:
  # -- The spotfire-server service name. This value is evaluated as a helm template.
  serverBackendAddress: ""
  # -- The draining timeout after which the service is forcefully shut down.
  preStopDrainingTimeoutSeconds: 610

replicaCount: 1

image:
  # image.registry -- The image registry for spotfire-server. Overrides global.spotfire.image.registry value.
  registry:
  # image.repository -- The spotfire-server image repository.
  repository: tibco/spotfire-terrservice
  # image.tag -- The container image tag to use.
  tag: "1.14.0-1.2.0"
  # image.pullPolicy -- The spotfire-server image pull policy. Overrides global.spotfire.image.pullPolicy.
  pullPolicy:
  ## Optionally specifies an array of imagePullSecrets.
  # image.pullSecrets -- spotfire-server image pull secrets.
  pullSecrets: []

fluentBitSidecar:
  image:
    # -- The image repository for fluent-bit logging sidecar.
    repository: fluent/fluent-bit
    # -- The image tag to use for fluent-bit logging sidecar.
    tag: "2.0.5"
    # -- The image pull policy for the fluent-bit logging sidecar image.
    pullPolicy: IfNotPresent

  # -- The securityContext setting for fluent-bit sidecar container. Overrides any securityContext setting on the Pod level.
  securityContext: {}
    # # -- Enable this if running as privileged.
    # privileged: false
    # # -- Enable this if running as NonRoot User.
    # runAsNonRoot: true
    # # -- User ID for the Container.
    # runAsUser: 1000
    # # -- Group ID for the Container.
    # runAsGroup: 0

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created.
  create: false
  # Annotations to add to the service account.
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, then a name is generated using the fullname template.
  name: ""

podAnnotations:
  prometheus.io/path: /spotfire/metrics
  prometheus.io/port: "9080"
  prometheus.io/scrape: "true"

# -- The Pod securityContext setting applies to all of the containers inside the Pod.
podSecurityContext: {}
  # # -- Owner User ID for the volume and any file created in that volume.
  # fsGroup: 1000
  # # -- User ID for the Pod.
  # runAsUser: 1000
  # # -- Group ID for the Pod.
  # runAsGroup: 0

# -- The securityContext setting for the spotfire-terrservice container. Overrides any securityContext setting on the Pod level.
securityContext: {}
  # # -- Enable this if running as privileged.
  # privileged: false
  # # -- Enable this if running as NonRoot User.
  # runAsNonRoot: true
  # # -- User ID for the Container.
  # runAsUser: 1000
  # # -- Group ID for the Container.
  # runAsGroup: 0

service:
  type: ClusterIP
  port: 9501

## The Spotfire node manager startup, readiness, and liveness probe initial delay and timeout.
## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
startupProbe:
  enabled: true
  httpGet:
    path: /spotfire/started
    port: registration
  initialDelaySeconds: 60
  periodSeconds: 3
  failureThreshold: 20
livenessProbe:
  enabled: true
  httpGet:
    path: /spotfire/liveness
    port: registration
  initialDelaySeconds: 60
  periodSeconds: 3
  failureThreshold: 10
readinessProbe:
  enabled: false
  httpGet:
    path: /spotfire/readiness
    port: registration
  initialDelaySeconds: 60
  periodSeconds: 3
  failureThreshold: 10

logging:
  # -- The spotfire-server log-forwarder name. Template.
  logForwarderAddress: ""
  ## -- set to `debug`, `trace`, `minimal` or leave empty for info.
  logLevel: "debug"

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This increases chances that charts can run on environments with few 
  # resources, such as Minikube. If you do want to specify resources, then uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- KEDA autoscaling configuration. See https://keda.sh/docs/latest/concepts/scaling-deployment for more details.
# @default -- Disabled
kedaAutoscaling:
  enabled: false
  # -- The interval to check each trigger on.
  pollingInterval: 30
  # -- The period to wait after the last trigger reported active before scaling the resource back to 0.
  cooldownPeriod: 300
  # -- The minimum number of replicas KEDA scales the resource down to.
  minReplicas: 1
  # -- This setting is passed to the HPA definition that KEDA creates for a given resource and holds the maximum number of replicas of the target resource.
  maxReplicas: 4
  threshold:
  fallback: {}
  triggers: []
  advanced: {}
  # -- Spotfire specific settings.
  spotfireConfig:
    # -- REQUIRED. The URL to the Prometheus server where metrics are fetched from.
    prometheusServerAddress: http://prometheus-server.monitor.svc.cluster.local

nodeSelector: {}

tolerations: []

affinity: {}

config:
  # -- If set, it will override the default [custom.properties](https://docs.tibco.com/pub/terrsrv/latest/doc/html/TIB_terrsrv_install/terrinstall/topics/custom_configuration_properties.html) file.
  conf/custom.properties: ""
  # --
  log4j2.xml: ""

# -- Additional environment variables.
extraEnvVars: []
#  - name: NAME
#    value: value

# The name of the ConfigMap containing additional environment variables.
extraEnvVarsCM: ""

# The name of the Secret containing extra additional environment variables.
extraEnvVarsSecret: ""

# -- Extra volumeMounts for the spotfire-terrservice container.
# More info: `kubectl explain deployment.spec.template.spec.containers.volumeMounts`
extraVolumeMounts: []
  # - name: example
  #   mountPath: /opt/tibco/example.txt
  #   subPath: example.txt

# -- Extra volumes for the spotfire-terrservice container.
# More info: `kubectl explain deployment.spec.template.spec.volumes`
extraVolumes: []
  # - name: example
  #   persistentVolumeClaim:
  #     claimName: exampleClaim

volumes:
  packages:
    mountPath: /opt/packages
    persistentVolumeClaim:
      # -- If 'true', then a 'PersistentVolumeClaim' is created.
      create: false
      # -- Specifies the name of the 'StorageClass' to use for the customExt volume-claim.
      storageClassName: ""
      # -- Specifies the standard Kubernetes resource requests and/or the limits for the customExt volume claims.
      resources:
        requests:
          storage: 1Gi
      # -- Specify the name of the persistent volume that should be used for the customExt volume-claim.
      volumeName:
    # When 'persistentVolumeClaim.create' is 'false', then this value can be used to define already existing
    # persistent volume claim
    existingClaim: ""

  troubleshooting:
    persistentVolumeClaim:
       # -- If 'true', then a 'PersistentVolumeClaim' will be created.
      create: false
      # -- Specify the name of the 'StorageClass' that should be used for the volumes.troubleshooting-claim.
      storageClassName: ""
      # -- Specifies the standard K8s resource requests and/or limits for the volumes.troubleshooting claims.
      resources:
        requests:
          storage: 2Gi
      # -- Specifies the name of the persistent volume to use for the volumes.troubleshooting-claim.
      volumeName:
    # -- When 'persistentVolumeClaim.create' is 'false', then use this value to define an already-existing
    # persistent volume claim.
    existingClaim: ""

# -- Additional init containers to add to the terrservice pod.
extraInitContainers: []
  # - name: dummy-init
  #   image: busybox
  #   command: ['echo', "hey"]
